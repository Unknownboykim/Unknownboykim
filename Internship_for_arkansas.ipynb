{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Unknownboykim/Unknownboykim/blob/main/Internship_for_arkansas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbGmh6_Po7ue"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from os import makedirs\n",
        "from os import listdir\n",
        "from shutil import copyfile\n",
        "from random import seed\n",
        "from random import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# visuals\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "from PIL import Image\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,confusion_matrix,ConfusionMatrixDisplay\n",
        "\n",
        "# Tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense,MaxPooling2D,Dropout,Flatten,BatchNormalization,Conv2D\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooz3y94zpsjn",
        "outputId": "950fcdf3-4f2b-4919-815c-10e6d9fa795b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSSwk2ZEp1Oq",
        "outputId": "1d115af8-0490-41b2-d98c-fa483e53ae7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.7.14)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content\"\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "mXieoJS6qAti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Step: Unzip train.zip into the correct folder"
      ],
      "metadata": {
        "id": "KH4TMwFqr3k-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c dogs-vs-cats\n",
        "!unzip dogs-vs-cats.zip -d /content/dogs-vs-cats\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc8SLec2qFgZ",
        "outputId": "ab140922-2198-408b-96eb-9ae96931f99d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Downloading dogs-vs-cats.zip to /content\n",
            " 99% 805M/812M [00:07<00:00, 82.8MB/s]\n",
            "100% 812M/812M [00:07<00:00, 121MB/s] \n",
            "Archive:  dogs-vs-cats.zip\n",
            "  inflating: /content/dogs-vs-cats/sampleSubmission.csv  \n",
            "  inflating: /content/dogs-vs-cats/test1.zip  \n",
            "  inflating: /content/dogs-vs-cats/train.zip  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/data/train\n",
        "!unzip -q /content/dogs-vs-cats/train.zip -d /content/data/train"
      ],
      "metadata": {
        "id": "LpsIfQzVrSmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Move images up one level"
      ],
      "metadata": {
        "id": "dxD9OM57ryz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/data/train/train/* /content/data/train/"
      ],
      "metadata": {
        "id": "XhoLHzFfrqPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remove the now-empty nested folder"
      ],
      "metadata": {
        "id": "qtl-HXoIrwfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rmdir /content/data/train/train"
      ],
      "metadata": {
        "id": "bG1lXXVursq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then: Run the Data Split Script"
      ],
      "metadata": {
        "id": "zY476QnisLeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil, random\n",
        "\n",
        "original_dir = '/content/data/train'\n",
        "base_dir = '/content/data_split'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "val_dir = os.path.join(base_dir, 'val')\n",
        "\n",
        "os.makedirs(train_dir + '/cat', exist_ok=True)\n",
        "os.makedirs(train_dir + '/dog', exist_ok=True)\n",
        "os.makedirs(val_dir + '/cat', exist_ok=True)\n",
        "os.makedirs(val_dir + '/dog', exist_ok=True)\n",
        "\n",
        "filenames = os.listdir(original_dir)\n",
        "random.shuffle(filenames)\n",
        "\n",
        "split_idx = int(0.8 * len(filenames))\n",
        "for i, fname in enumerate(filenames):\n",
        "    src = os.path.join(original_dir, fname)\n",
        "    label = 'cat' if 'cat' in fname else 'dog'\n",
        "    dst_dir = train_dir if i < split_idx else val_dir\n",
        "    shutil.copy(src, os.path.join(dst_dir, label, fname))\n"
      ],
      "metadata": {
        "id": "WKalOt9RrZXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART 2: Build, Train, and Evaluate the CNN\n",
        "Step 1: Import Required Libraries"
      ],
      "metadata": {
        "id": "b0Y9zXUHsc_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "4fWDbn3oshIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Define Your CNN Model"
      ],
      "metadata": {
        "id": "yudnlsCmstA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification (dog vs cat)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuZ1gocJsuXp",
        "outputId": "0ff48cfe-4e9a-463a-b740-b51cc0e043d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Load Your Training and Validation Data"
      ],
      "metadata": {
        "id": "OS-tVtIBsyZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    '/content/data_split/train',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "val_data = val_datagen.flow_from_directory(\n",
        "    '/content/data_split/val',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrdnKhwgszSl",
        "outputId": "d4997e50-6495-4815-9f4e-860281c7bd59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 images belonging to 2 classes.\n",
            "Found 5000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Train the Model"
      ],
      "metadata": {
        "id": "P_bqi19ks7xT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_data,\n",
        "    epochs=10,\n",
        "    validation_data=val_data\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujNN4oLMs0l6",
        "outputId": "8c533ea4-f616-41e9-b392-06d6f585fe10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1231s\u001b[0m 2s/step - accuracy: 0.5920 - loss: 0.8467 - val_accuracy: 0.6574 - val_loss: 0.6229\n",
            "Epoch 2/10\n",
            "\u001b[1m 70/625\u001b[0m \u001b[32m‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m17:16\u001b[0m 2s/step - accuracy: 0.6896 - loss: 0.5925"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Plot Accuracy and Loss"
      ],
      "metadata": {
        "id": "vSyJBNUttAJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy plot\n",
        "plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "plt.title('Accuracy over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Loss plot\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fuBGnghitB-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Save the Trained Mode"
      ],
      "metadata": {
        "id": "z1U7X-iltFug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Local\n",
        "model.save('/content/cats_vs_dogs_model.h5')\n",
        "\n",
        "# Or to Google Drive\n",
        "# model.save('/content/drive/MyDrive/cats_vs_dogs_model.h5')\n"
      ],
      "metadata": {
        "id": "YOPPjAj1tHHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Run a Prediction on a Single Image"
      ],
      "metadata": {
        "id": "XYPRBl_utJXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Load and preprocess image\n",
        "img_path = '/content/data_split/val/cat/cat.4001.jpg'  # You can choose any image\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "x = image.img_to_array(img) / 255.0\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "# Predict\n",
        "prediction = model.predict(x)\n",
        "print(\"Prediction:\", \"Dog üê∂\" if prediction[0][0] > 0.5 else \"Cat üê±\")\n"
      ],
      "metadata": {
        "id": "xxuPSg4ftKFt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}